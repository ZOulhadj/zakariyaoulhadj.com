<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Zakariya Oulhadj</title>
        <link>http://localhost:1313/</link>
        <description>Recent content on Zakariya Oulhadj</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-gb</language>
        <lastBuildDate>Wed, 27 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Parallel Cellular Automaton Simulation</title>
        <link>http://localhost:1313/posts/parallel-cellular-automaton-simulation/</link>
        <pubDate>Wed, 27 Nov 2024 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/posts/parallel-cellular-automaton-simulation/</guid>
        <description>&lt;p&gt;As part of the Message-Passing Programming (&lt;a class=&#34;link&#34; href=&#34;http://www.drps.ed.ac.uk/24-25/dpt/cxepcc11002.htm&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;EPCC11002&lt;/a&gt;) course, I developed a
parallel implementation of a 2D-decomposed cellular automaton with periodic
boundary conditions on the \(i^{th} \) dimension. The boundary conditions for \(
\frac{2}{3} \)​ of the \( j^{th} \) dimension are set to alive cells. A
termination condition is imposed for the simulation in which the program
terminates if the number of living cells is below 3/4 or greater than 4/3 of the
initial living cells. The implementation uses MPI and a cartesian virtual
topology to decompose the grid into two dimensions where each process receives a
subsection of the grid. Communication between processes is performed using
halo-swapping via non-blocking point-to-point communication (MPI_Isend and
MPI_Irecv).&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;http://localhost:1313/img/posts/mpp-cellular-automaton.jpg&#34;&gt;
&lt;/figure&gt;

</description>
        </item>
        <item>
        <title>Member of TeamEPCC for the ISC25</title>
        <link>http://localhost:1313/posts/member-of-teamepcc-for-the-isc25/</link>
        <pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/posts/member-of-teamepcc-for-the-isc25/</guid>
        <description>&lt;p&gt;Recently I&amp;rsquo;ve been accepted into TeamEPCC which will be competing in the
International Student Cluster Compeition 2025 from April 1st to May 9th. Looking
forward to working with the team!&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;http://localhost:1313/img/posts/teamepcc.png&#34;&gt;
&lt;/figure&gt;

</description>
        </item>
        <item>
        <title>OpenMP Thread Contention Performance Investigation</title>
        <link>http://localhost:1313/posts/openmp-thread-contention-perf-investigation/</link>
        <pubDate>Fri, 25 Oct 2024 00:00:00 +0100</pubDate>
        
        <guid>http://localhost:1313/posts/openmp-thread-contention-perf-investigation/</guid>
        <description>&lt;p&gt;As part of the Threaded Programming (&lt;a class=&#34;link&#34; href=&#34;http://www.drps.ed.ac.uk/25-26/dpt/cxepcc11003.htm&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;EPCC11003&lt;/a&gt;) course, I investigated the
performance of three solver implementations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solver 1 (Recursive Tasks)&lt;/li&gt;
&lt;li&gt;Solver 2 (Shared Queue)&lt;/li&gt;
&lt;li&gt;Solver 2 (Separate Queues)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The original serial implementation provided uses a divide-and-conquer algorithm
for an adaptive quadrature method that computes the integral of a function on a
closed interval. The algorithm starts by applying two quadrature rules (3-point
and 5-point Simpson’s rules) to the whole interval. If the difference between
the integral estimates from the two rules is small enough (or the interval is
too short), the result in added to the total integral estimate. If it is not
small enough, the interval is split into two equal halves, and the method is
applied recursively to each halves, and the method is applied recursively to
each half. The evaluating the function requires the solution of an ODE (ordinary
differential equation) which is relatively expensive in time.&lt;/p&gt;
&lt;h2 id=&#34;solver-1--recursive-tasks&#34;&gt;&lt;a href=&#34;#solver-1--recursive-tasks&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Solver 1 (Recursive Tasks)
&lt;/h2&gt;&lt;p&gt;The first program, Solver 1, implements the divide-and-conquer algorithm
recursively using OpenMP tasks. A parallel region is created at the root simpson
function call, executed by a single thread. During the recursive process, when
an interval is divided into two, a new task is created for each half. Before
returning from a recursive call, a taskwait directive is used to ensure that
both subtasks have finished execution.&lt;/p&gt;
&lt;p&gt;The execution times indicate two varying performance characteristics between ICC
v20.4 (Intel C/C++ Compiler) and GCC v10.2.0 (GNU Compiler Collections). The
Intel compiler consistently outperforms GCC on all thread counts, showing strong
scalability. This can be attributed to compiler optimisations which produce more
efficient assembly instructions for the Intel Xeon E5- 2695 processor used on
the Cirrus compute node. Beyond 16 threads, GCC performance deteriorates
significantly, with a sharp increase in execution time and therefore, decline in
scalability. The runtime disparity between the compilers reaches 11.776 seconds
on 32 threads. Inefficiencies in the compiler and increased overhead associated
with task creation may be the contributing factors. Further analysis was carried
out to determine whether these results were specifically isolated to GCC version
10.2.0. Versions 8.2.0 and 12.3.0 exhibited similar behaviour, suggesting that
the issue may stem from a long- standing bug or inefficiency in the compiler’s
code generation. The results are also shown in terms of speed up indicating that
ICC was able to achieve the highest speed-up of 20.995x compared to GCC 2.143x
on 32 threads.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/img/posts/solver_1_execution_time.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt; &lt;img src=&#34;http://localhost:1313/img/posts/solver_1_speed_up.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;solver-2--shared-queue&#34;&gt;&lt;a href=&#34;#solver-2--shared-queue&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Solver 2 (Shared Queue)
&lt;/h2&gt;&lt;p&gt;Solver 2 implements the same algorithm but utilises a LIFO (Last-In-First-Out)
queue for managing intervals. OpenMP locks were introduced to ensure thread-safe
enqueuing and dequeuing operations on the shared queue. The termination criteria
was revised to account for scenarios where the queue might be empty while
intervals are still being processed. As a result, the computation only completes
when the queue is empty and no threads remain active.&lt;/p&gt;
&lt;p&gt;The execution times for both the ICC and GCC compilers are similar, with
standard deviations of 8.084 and 7.719 seconds, respectively. Execution times
generally decrease as the number of threads increases. However, beyond 16
threads, both compilers exhibit an increase in execution time of approximately
3.567 seconds, with performance becoming more irregular. This is attributed to
the synchronisation overhead introduced by frequent locking and unlocking of the
shared queue as threads compete for access. Consequently, the performance gains
achievable with this implementation are inherently limited by this bottleneck,
highlighting the need for alternative approaches. Another factor affecting
performance is the lack of load balancing, which results in certain threads
having more work whilst others are idle.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/img/posts/solver_2_1_execution_time.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt; &lt;img src=&#34;http://localhost:1313/img/posts/solver_2_1_speed_up.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;solver-2--separate-queues&#34;&gt;&lt;a href=&#34;#solver-2--separate-queues&#34; class=&#34;header-anchor&#34;&gt;&lt;/a&gt;Solver 2 (Separate Queues)
&lt;/h2&gt;&lt;p&gt;To address the performance limitations of using a shared queue, a second
implementation of Solver 2 was developed in which each thread maintains its own
separate queue. If the current threads queue is not empty, then an interval is
dequeued. However, if it is empty, then the thread attempts to &amp;ldquo;steal work&amp;rdquo; from
another thread for processing. Work is distributed in a round-robin fashion to
ensure load balancing, keeping the number of tasks in each thread’s queue
roughly equal. Each queue access is again synchronised using OpenMP locks.&lt;/p&gt;
&lt;p&gt;Performance results, demonstrate a significant improvement compared to the first
Solver 2 using a single queue. The program reduces contention for queue access,
as each thread operates on its queue, leading to better scalability with larger
thread counts, aligning with Amdahl&amp;rsquo;s Law. The execution time is comparable to
that of Solver 1 using the ICC compiler. The speed up increasing sub-linearly
for both compilers, reaching a maximum of 20.174x and 21.523x for ICC and GCC
respectively on 32 threads.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/img/posts/solver_2_2_execution_time.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt; &lt;img src=&#34;http://localhost:1313/img/posts/solver_2_2_speed_up.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Further investigation into queue contention measured average accesses per second
comparing Solver 2 with a single shared queue versus Solver 2 using separate
queues. The access difference between the two implementations. It verifies that
using a single queue causes contention between threads whereas using separate
queues can achieve greater accesses per second.&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;http://localhost:1313/img/posts/solver_2_1_vs_2_2_access_time.jpg&#34;&gt;
&lt;/figure&gt;

&lt;p&gt;The downside to this approach, however, is that total memory utilisation
increases to 34.56 MB com- pared to 0.48 MB for a single queue. This balance
between performance and memory usage is a common factor that needs to be
considered when implementing high performance software. Overall, the findings of
this report highlight the impact of resource contention on a program’s
efficiency. In- creasing the number of threads alone does not guarantee
improvements. By addressing bottlenecks in queue accesses, both efficiency and
scalability are enhanced, which is essential for managing large workloads in
High-Performance Computing.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Studying High Performance Computing</title>
        <link>http://localhost:1313/posts/studying_hpc/</link>
        <pubDate>Sun, 02 Jun 2024 00:00:00 +0100</pubDate>
        
        <guid>http://localhost:1313/posts/studying_hpc/</guid>
        <description>&lt;p&gt;I have recently been offered a place at University of Edinburgh to study High
Performance Computing (HPC) for my postgraduate degree. This is an amazing
opportunity and one which I am extremely grateful for. It is a big step up for
me both academically as well as for my future career aspirations and I am really
looking forward to starting in September.&lt;/p&gt;
&lt;p&gt;My decision to study this course stems from my profound interest in software
development and hardware architecture with a particular focus on performance
optimisation. Understanding how these two interoperate will enable me to address
the computational challenges inherent in modern software. Being taught by
professors and experts from EPCC and the University would give me the invaluable
knowledge and skills to make an impact in my future career as a software
engineer. Specialising in performance optimisation would also prepare me to
potentially pursue further research for a PHD in HPC.&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;http://localhost:1313/img/posts/edinburgh_university.jpg&#34;&gt;
&lt;/figure&gt;

</description>
        </item>
        <item>
        <title>Using Linux in 2024 (Part 2)</title>
        <link>http://localhost:1313/posts/using-linux-in-2024-part-2/</link>
        <pubDate>Wed, 29 May 2024 00:00:00 +0100</pubDate>
        
        <guid>http://localhost:1313/posts/using-linux-in-2024-part-2/</guid>
        <description>&lt;p&gt;Having daily driven my Linux laptop (Arch btw) for 6 months now I have quite a
few observations. The main issue I’ve had is full system reboots due to the
amdgpu GPU driver crashing. After a few months of investigation I believe that
the core of the issue is related to P-State and how the CPU manages power.
Having said this, I have not had a crash for at least a month now so heres
hoping that it has been fixed in a recent update.&lt;/p&gt;
&lt;p&gt;Other than that, everything else has been pretty enjoyable especially because of
how fast Linux is compared to Windows. Occasionally, I will use my Windows
desktop and perform simple tasks such as clicking on different web pages,
opening Visual Studio or just interacting with the file explorer which feels
sluggish. This is not the case on Linux which performs great even under heavy
workloads.&lt;/p&gt;
&lt;p&gt;As a programmer, I have to say, working on Windows is a pain. Many tools that
are commonplace on Linux are simply not available and even if they are, I have
to deal with installation directories being totally random as well as poor
performance. For example, running git pull takes a good 2 seconds just to run
the program whereas on Linux its seemingly instant. To be fair, this could be as
a result of a another issue but I am not totally sure.&lt;/p&gt;
&lt;p&gt;Overall, I’m pretty happy with how things are going and will see how things go
towards the end of the year and if I will continue using Linux full time.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Vulkan Model Viewer and Exporter (VMVE)</title>
        <link>http://localhost:1313/projects/vmve/</link>
        <pubDate>Sun, 21 Apr 2024 00:00:00 +0100</pubDate>
        
        <guid>http://localhost:1313/projects/vmve/</guid>
        <description></description>
        </item>
        <item>
        <title>Using Linux in 2024 (Part 1)</title>
        <link>http://localhost:1313/posts/using-linux-in-2024-part-1/</link>
        <pubDate>Mon, 29 Jan 2024 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/posts/using-linux-in-2024-part-1/</guid>
        <description>&lt;p&gt;I have known about Linux for several years and have attempted multiple times to
fully transition over from Windows/macOS. So far, these attempts have been
unsuccessful for numerous reasons. For example, software not being supported on
Linux, lack of features or issues such as failing to wake from sleep, freezing
and applications crashing caused by driver bugs.&lt;/p&gt;
&lt;p&gt;As an aspiring programmer, I know how beneficial Linux is and how much easier
software development becomes. This is why, I have made it one of my goals to
fully transition over to Linux. Throughout 2024, I would like to better
understand the underlying operating system, create my own dotfiles and use Linux
on a daily basis.&lt;/p&gt;
&lt;p&gt;At the moment, I am using Ubuntu with i3 as my window manager. Over time, once
my dotfiles are more or less complete then I would like to move over to Arch due
to its simplicity, AUR and its rolling-release architecture.&lt;/p&gt;
&lt;p&gt;If all goes well, I will be making a follow up post in six months time to
showcase my progress including the things I have learnt at the half way mark.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Graduating in Computer Science from The University of Roehampton</title>
        <link>http://localhost:1313/posts/graduating-in-computer-science/</link>
        <pubDate>Thu, 28 Sep 2023 00:00:00 +0100</pubDate>
        
        <guid>http://localhost:1313/posts/graduating-in-computer-science/</guid>
        <description>&lt;p&gt;I am very happy to announce that I’ve graduated with First Class Honours in
Computer Science from The University of Roehampton 🎉. It has been a long but
fulfilling experience with many ups and downs along the way and I’d like to
thank my family, friends and professors who have supported me. This is a big
milestone for me and one which can hopefully open the door for many
opportunities going forward.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
